
# FPS Logs Analyzer

Este projeto analisa logs de partidas de jogos FPS e gera estatÃ­sticas detalhadas de jogadores e partidas, utilizando Node.js e NestJS.

## Requisitos

Para mais detalhes sobre os requisitos e funcionalidades, veja o arquivo `docs/specs.MD`.

### Principais Rotas ğŸ“¡

- `GET /ranking` â€” Retorna o ranking global de jogadores. 
- `GET /:externalId/ranking` â€” Retorna o ranking de uma partida especÃ­fica. 
- `POST /upload` â€” Realiza o upload de um arquivo de log para processamento. 
- `GET /health` â€” Endpoint de verificaÃ§Ã£o de saÃºde da aplicaÃ§Ã£o. 

Na pasta ```docs/postman``` vocÃª encontra uma coleÃ§Ã£o do Postman com exemplos de requisiÃ§Ãµes para testar a API. ğŸ“¨

### ğŸ› ï¸ Tecnologias Utilizadas 
- Node.js
- NestJS
- Prisma ORM 
- EventEmitter para eventos assÃ­ncronos
- Multer para upload de arquivos
- Zod 
- Vitest para testes unitÃ¡rios

### ğŸ—ï¸ Como Executar 

obs: Certifique-se de ter o Docker e o Docker Compose instalados.

```bash
docker-compose up -d
```


O projeto por padrÃ£o configurado no docker-compose irÃ¡ rodar no endereÃ§o ğŸŒ `http://localhost:3000`. 

## ğŸ—„ï¸ Entidades do Banco de Dados

O sistema utiliza as seguintes entidades principais para persistÃªncia dos dados:

- **Player**: Representa um jogador, armazenando nome e identificador Ãºnico.
- **Match**: Representa uma partida, com identificador externo, data de inÃ­cio e fim.
- **MatchParticipation**: Relaciona um jogador a uma partida, armazenando frags, mortes, streaks, prÃªmios e estatÃ­sticas individuais.
- **Frag**: Representa uma eliminaÃ§Ã£o (frag) ocorrida na partida, incluindo quem matou, quem foi morto, arma utilizada e timestamp.

Essas entidades estÃ£o modeladas no arquivo `prisma/schema.prisma` e sÃ£o utilizadas para gerar as tabelas do banco de dados via Prisma ORM.

O relacionamento entre elas permite calcular rankings, estatÃ­sticas globais e por partida, alÃ©m de rastrear streaks e prÃªmios especiais.

### âš¡ DecisÃ£o de Design: Processamento AssÃ­ncrono com Eventos 

O processamento dos arquivos de log Ã© realizado de forma assÃ­ncrona utilizando o padrÃ£o de eventos (EventEmitter). Essa abordagem traz os seguintes benefÃ­cios:

- **Desacoplamento**: O upload do arquivo e o processamento dos dados sÃ£o separados, permitindo que a API responda rapidamente ao usuÃ¡rio e processe os dados em segundo plano. 
- **Escalabilidade**: O uso de eventos facilita a extensÃ£o do sistema para mÃºltiplos tipos de processamento ou integraÃ§Ãµes futuras (ex: notificaÃ§Ãµes, persistÃªncia em diferentes bancos, etc). 
- **ManutenÃ§Ã£o**: O fluxo de eventos torna o cÃ³digo mais modular, facilitando testes e manutenÃ§Ã£o. 

#### ğŸ”€ Fluxo de Processamento 
1. O usuÃ¡rio faz upload do arquivo de log via endpoint (`POST /upload`).  
   **Arquivo:** `src/infra/http/controllers/logs.controller.ts`
2. O serviÃ§o de upload dispara um evento interno indicando que um novo arquivo estÃ¡ disponÃ­vel para processamento.  
   **Arquivo:** `src/infra/events/event.service.ts`
3. O worker de processamento escuta esse evento, lÃª o arquivo, interpreta os eventos do log e atualiza as entidades (jogadores, partidas, participaÃ§Ãµes, frags) no banco de dados.  
   **Arquivo:** `src/infra/workers/log-worker.service.ts` e `src/app/use-cases/process-match.use-case.ts`
4. O processamento Ã© realizado de forma assÃ­ncrona, sem bloquear a resposta ao usuÃ¡rio.  
   **Arquivos envolvidos:** Todos acima, integrados via EventEmitter.
5. ApÃ³s o processamento, os dados ficam disponÃ­veis para consulta via API.  
   **Arquivo:** `src/infra/http/controllers/global-player-ranking.controller.ts`, `src/infra/http/controllers/match-ranking.controller.ts`

Esse padrÃ£o garante que o sistema seja responsivo e preparado para lidar com grandes volumes de dados ou mÃºltiplos uploads simultÃ¢neos.


## ğŸ› ï¸ Testes

Para executar os testes, utilize o comando:

```bash
npm run test:unit
```

O projeto utiliza o Vitest como framework de testes, com cobertura de testes configurada.

Para os testes unitÃ¡rios, foram criados mocks de repositÃ³rios com implementaÃ§Ãµes InMemory para simular o comportamento do banco de dados. Isso permite testar a lÃ³gica de negÃ³cios sem depender de uma instÃ¢ncia real do banco de dados. Esses arquivos estÃ£o localizados na pasta `test/repositories`.